# LinkedIn Content: AI, jailbreaks, and 150GB of unanswered questions

Source: `/workspace/content/ai-jailbreaks-and-150gb-of-unanswered-questions.md`

---

## LinkedIn Text Post

A hacker reportedly jailbroke Claude to breach Mexican government agencies and exfiltrate 150GB of data. I tried to verify the claims.

Everything traces back to one source: Gambit Security, an Israeli startup that emerged from stealth the same day as the story. Two of the five agencies denied being breached. Three didn't comment. Anthropic confirmed misuse and banned accounts but didn't confirm the scale. No stolen data has surfaced on leak forums.

The Mexico story is more nuanced than the headlines suggest. My full source analysis and take is in the blog post.

What's not ambiguous: end-to-end AI attacks are already documented. Anthropic published a case last November where a Chinese state-sponsored group ran Claude autonomously, 80-90% of operations without human intervention.

Also this week: Check Point found RCE flaws in Claude Code through project hooks. Orca Security showed Copilot leaking tokens from Codespaces via hidden prompts. An amateur used AI to own 600+ FortiGate devices across 55 countries. And three Chinese AI firms ran 16 million queries through 24,000 fake accounts to steal Anthropic's model.

Full roundup at accidentalrebel.com/ai-jailbreaks-and-150gb-of-unanswered-questions

#AISecurity #CyberSecurity #ThreatIntel #LLMSecurity #AIAgentSecurity

---

## Carousel Plan

### Visual Identity

- Background: #ffffff (white)
- Accent color: #dc2626 (red)
- Text color: #24292f (dark gray)
- Text muted: #656d76
- Subtle background: #f6f8fa (light gray)
- Border: #d0d7de
- Style: Clean minimal, white-dominant with red accents
- Typography: Clean sans-serif, bold headlines top-left
- Motif: Minimal — thin red lines, subtle geometric touches
- Dimensions: 1080x1350
- Constraints: No photorealism, no clutter, professional, white/red palette

---

### Slide 1 (Cover)

**Headline:** "AI, Jailbreaks, and 150GB of Unanswered Questions"
**Supporting text:** Weekly AI Security Roundup — Feb 27, 2026
**Visual note:** Use the Gemini-generated blog image as full-bleed background. Apply a dark gradient overlay (bottom-heavy) for text readability. Title in white, large. Corner brackets and series marker in white/semi-transparent. No dot texture on this slide — the image replaces it.

---

### Slide 2 (Core)

**Headline:** "Claude Jailbroken for Government Hacking?"
**Supporting text:** A hacker reportedly jailbroke Claude to exfiltrate 150GB from Mexican agencies. I tried to verify the claims.
**List items:**
- All information traces to one source: Gambit Security
- Two agencies denied breaches. Three didn't comment.
- Anthropic confirmed misuse but not the scale
- No stolen data has surfaced on leak forums
**Concluding line:** The details matter. Full source analysis in the blog.

---

### Slide 3 (Core)

**Headline:** "AI Dev Tools Under Attack"
**Supporting text:** Three disclosures this week showed AI coding assistants trusting inputs they shouldn't.
**List items:**
- Trail of Bits extracted private Gmail data through Perplexity's Comet browser via prompt injection
- Claude Code had RCE flaws: opening an untrusted repo could trigger code execution through project hooks
- RoguePilot: hidden prompts in GitHub issues made Copilot exfiltrate GITHUB_TOKEN from Codespaces
**Concluding line:** Configuration files in AI dev tools are now an execution layer.

---

### Slide 4 (Core)

**Headline:** "AI Turns Amateurs Into Operators"
**Supporting text:** Low-skill attackers are using AI to punch above their weight. Two cases this week:
**List items:**
- A "low-to-average" threat actor used DeepSeek, Claude, and a custom MCP server to compromise 600+ FortiGate devices across 55 countries
- Three Chinese firms ran 16 million queries through 24,000 fake accounts to steal Anthropic's model via distillation
- Anthropic documented a separate case: a state-sponsored group ran Claude 80-90% autonomously
**Concluding line:** The skill floor for offensive operations is dropping fast.

---

### Slide 5 (Core)

**Headline:** "Also This Week"
**Supporting text:** Four more stories from the AI security intersection.
**List items:**
- LLMs generate predictable passwords — systematic patterns, often starting with "G7"
- Journalist poisoned AI training data in 24 hours with a fake expertise website
- Chinese police leaked a ChatGPT-powered influence operation targeting Japan's PM
- CrowdStrike: AI tools and credential misuse are collapsing breakout times to 29 minutes
**Concluding line:** AI-assisted intrusion is now standard operating procedure.

---

### Slide 6 (Core)

**Headline:** "The Mexico Story Has Layers"
**Supporting text:** The editorial on the Claude/Mexico case is more nuanced than a carousel can capture. Bloomberg's reporting contains ambiguous claims about what Claude did versus what the human operator did. My full source analysis, with links to every agency denial, is in the blog post.
**List items:** _(None — this is a text-only slide)_
**Concluding line:** Read the full breakdown at accidentalrebel.com

---

### Slide 7 (Closing)

**Headline:** "Full roundup at accidentalrebel.com"
**Supporting text:** Juan Karlo Licudine / @accidentalrebel
**Visual note:** Clean close — centered text, red URL, author name. No list.
